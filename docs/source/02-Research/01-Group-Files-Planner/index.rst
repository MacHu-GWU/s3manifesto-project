.. _group-files-planner:

Group Files Planner
==============================================================================
在大数据处理中, 经常会用到分儿治之的策略. 举例来说, 在百万级文件数量的数据处理中, 会有如下应用场景:

- 将文件分成小组, 例如每组 1000 个文件, 交给许多分布式的 worker 并行处理, 提高处理速度.
- 对 datalake 中的数据文件做 compaction, 将小文件合并使得文件的 IO 次数减少, 数据更有序, 查询性能更高.

这种分而治之的应用场景的核心技术是将文件按照大小 (或是里面的数据量, 通常是行数) 聚合成固定大小 (不是严格等于, 大致就可以) 的 Group. 在数据量很大的时候, 选择一个高性能的分组算法就变得很重要了.


Implementation and Performance Benchmark
------------------------------------------------------------------------------
下面这个脚本我们分别用纯 Python 和用 polars 库实现了这个算法, 并测试了性能.

.. dropdown:: group_files_planner_poc.py

    .. literalinclude:: ./group_files_planner_poc.py
       :language: python
       :linenos:

结论:

对于 1M 个文件进行测试, 纯 Python 实现大约是 0.5 秒, 而 Polars 实现大约是 1 秒. 随着文件的数量增加耗时也 1:1 线性增加. 在 100M 个文件时纯 Python 实现大约是 50 秒. 而 Polars 实现大约是 100 秒.

所以我的项目中主要采用纯 Python 实现的算法.


Dispatcher Use Case
------------------------------------------------------------------------------
在大数据处理时, 我们往往会 Orchestrator 扫描全部文件的 metadata, 然后将其分成小组分发给 Worker 来处理. 那么根据以上的 benchmark, 我们以 1M 个文件为基准, 0.5 秒处理完任务分配工作. 我们按照 Amazon Order 数据集大约 100K 条数据压缩后是 20MB, 未压缩大约是 150MB 为参照物. 也就是我们在 0.5 秒内完成了一个 1M * 100K = 100B 条数据, 1M * 20MB = 20TB 压缩后的数据 (未压缩则是 150TB) 的数据集的编排任务. 只要分配工作这一个必须由单点处理的工作抗住了压力, 后续就都是分而治之分布式处理的工作了. 可见即使数据量再大一百倍, 也就是 10 Trillion 条数据, 2PB 压缩后的数据该算法也能胜任. 证明了这一算法的可扩展性.
